\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{float}

% Page Geometry
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}

% Code Listing Configuration
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\title{\textbf{Implementation Guide: Epidemic Replication}\\ \large Distributed Systems - Exercise 4}
\author{Generated Guide}
\date{\today}

\begin{document}

\maketitle

\section{Overview}
This document outlines the architecture and implementation steps for the distributed epidemic replication system. The system requires implementing a multi-versioned data architecture across three layers using Python[cite: 12, 65].

\section{System Topology \& Requirements}
The system consists of 7 nodes divided into three layers, each with distinct consistency guarantees and replication strategies[cite: 23].

\subsection{1. Core Layer (Strong Consistency)}
\begin{itemize}
    \item \textbf{Nodes:} A1, A2, A3 (Fully connected triangle) [cite: 46--49].
    \item \textbf{Data Version:} Holds the most modern versions $V=n$[cite: 20].
    \item \textbf{Strategy:} Update Everywhere, Active, Eager Replication[cite: 33].
    \item \textbf{Behavior:} When a node receives an update, it must broadcast it to all other core nodes and wait for acknowledgement before confirming the write.
\end{itemize}

\subsection{2. Layer 1 (Causal Consistency)}
\begin{itemize}
   \item \textbf{Nodes:} B1, B2[cite: 50, 51].
    \item \textbf{Topology:} A2 connects to B1; A3 connects to B2[cite: 26].
    \item \textbf{Strategy:} Passive, Primary Backup[cite: 34].
    \item \textbf{Trigger:} Lazy propagation. Updates are sent every \textbf{10 updates}[cite: 34].
\end{itemize}

\subsection{3. Layer 2 (Weak Consistency)}
\begin{itemize}
    \item \textbf{Nodes:} C1, C2[cite: 53, 55].
    \item \textbf{Topology:} B2 connects to both C1 and C2[cite: 26].
    \item \textbf{Strategy:} Passive, Primary Backup[cite: 35].
    \item \textbf{Trigger:} Lazy propagation. Updates are sent every \textbf{10 seconds}[cite: 35].
\end{itemize}

\section{Implementation Steps}

\subsection{Step 1: Protocol \& Node Structure}
Communication must use Sockets or gRPC[cite: 32]. A generic \texttt{Node} class is recommended.

\begin{lstlisting}[language=Python, caption=Node Skeleton]
import socket
import threading
import time
import json

class Node:
    def __init__(self, node_id, port, neighbors, layer):
        self.node_id = node_id
        self.port = port
        self.neighbors = neighbors 
        self.layer = layer
        self.data_log = []
        self.update_count = 0 
        
        # Start listening for connections
        threading.Thread(target=self.start_server, daemon=True).start()
        
        # Start background timer for Layer 2 (B2 -> C1, C2)
        if self.node_id == "B2":
            threading.Thread(target=self.layer2_timer, daemon=True).start()

    def start_server(self):
        # Socket setup code here...
        pass
\end{lstlisting}

\subsection{Step 2: Core Layer Logic (Eager)}
The Core layer must handle "Active" and "Eager" replication. This implies blocking the response until peers acknowledge the update.

\begin{lstlisting}[language=Python, caption=Core Request Handling]
def handle_client_update(self, data):
    if self.layer == 'CORE':
        # 1. Active: Broadcast to peers (A1 -> A2, A3)
        acks = 0
        for peer in self.core_peers:
            if self.send_request(peer, "REPLICATE", data) == "ACK":
                acks += 1
        
        # 2. Eager: Wait for ACKs
        if acks == len(self.core_peers):
            self.commit_update(data)
            return "SUCCESS"
    return "FAIL"
\end{lstlisting}

\subsection{Step 3: Propagation Logic (Lazy)}
Nodes A2, A3, and B2 have specific triggers for propagating data downwards.

\begin{lstlisting}[language=Python, caption=Propagation Triggers]
def commit_update(self, data):
    self.data_log.append(data)
    self.write_log_to_file() # Requirement [cite: 36]
    
    # Layer 1 Trigger (A2/A3): Every 10 updates [cite: 34]
    if self.node_id in ['A2', 'A3']:
        self.update_count += 1
        if self.update_count % 10 == 0:
            target = 'B1' if self.node_id == 'A2' else 'B2'
            self.propagate_state(target)

def layer2_timer(self):
    # Layer 2 Trigger (B2): Every 10 seconds [cite: 35]
    while True:
        time.sleep(10)
        self.propagate_state('C1')
        self.propagate_state('C2')
\end{lstlisting}

\section{Transaction Processing}
The client reads a transaction file. 
\begin{itemize}
    \item \textbf{Read-Only:} Format \texttt{30 49 69} (ends with layer ID). Can be executed on any layer[cite: 38].
    \item \textbf{Update:} Format \texttt{12 49.53 69}. Must always be executed on a Core node[cite: 41, 43].
\end{itemize}

\section{Monitoring}
A web application is required to monitor replicas in real-time via WebSockets[cite: 44].
\begin{itemize}
    \item \textbf{Backend:} Use a lightweight server (e.g., \texttt{FastAPI} or \texttt{Flask-SocketIO}) to receive status updates from nodes.
    \item \textbf{Frontend:} HTML/JS Dashboard to visualize the length and content of version logs across all 7 nodes.
\end{itemize}

\end{document}